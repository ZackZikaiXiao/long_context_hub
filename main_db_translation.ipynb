{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f27ac87c-4c1f-49fa-87c0-02ef95ae580b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "安装包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5c0f0bc-b4a7-4dc4-970b-8d947cf9118b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%pip install -r requirements.txt\n",
    "%pip install \"deepspeed==0.14.0\" --upgrade\n",
    "%pip install modelscope\n",
    "%pip install flash-attn --no-build-isolation\n",
    "\n",
    "!pip install accelerate==0.26.1\n",
    "!pip install bitsandbytes==0.42.0\n",
    "!pip install ctranslate2==3.24.0\n",
    "!pip install datasets==2.16.1\n",
    "!pip install peft==0.7.1\n",
    "!pip install trl==0.7.10\n",
    "!pip install typing-extensions==4.7.1\n",
    "!pip install transformers==4.41.1\n",
    "!pip install sentencepiece\n",
    "!pip install sacrebleu sentencepiece -q\n",
    "!pip install flash-attn --no-build-isolation\n",
    "!pip install pandas\n",
    "!pip install cdifflib\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1afb342-0f10-495d-9241-3c2e240ad46b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f2ea1d1-81e4-4b3e-b535-57381adbce6a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "LoRA训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "282d5361-3cbd-4f04-b743-273cbd620b47",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.ml.torch.distributor import TorchDistributor\n",
    "import mlflow\n",
    "import torch\n",
    "os.environ[\"NCCL_DEBUG\"] = \"INFO\"\n",
    "os.environ[\"NCCL_IGNORE_DISABLED_P2P\"] = \"1\"\n",
    "os.environ[\"NCCL_P2P_DISABLE\"] = \"1\"\n",
    "os.environ[\"TORCH_EXTENSIONS_DIR\"] = \"/root/.cache/torch_extensions/py310_cu118\"\n",
    "host = \"https://\" + spark.conf.get(\"spark.databricks.workspaceUrl\")\n",
    "os.environ[\"DATABRICKS_HOST\"] = host\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = mlflow.utils.databricks_utils.get_databricks_host_creds().token\n",
    "username = spark.sql(\"SELECT current_user()\").first()['current_user()']\n",
    "experiment_path = f'/Users/{username}/finetune-aya-8b'\n",
    "mlflow.set_experiment(experiment_path)\n",
    "os.environ[\"EXPERIMENT_PATH\"] = experiment_path\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n",
    "\n",
    "# 设置参数\n",
    "base_path = \"/Volumes/main/default/default_volume/erikyzzhang/HOK\"\n",
    "model_name_or_path = base_path + \"/models/models--CohereForAI--aya-23-8B\"\n",
    "model_max_length = 256\n",
    "output_dir = base_path + \"/models/\"\n",
    "data_path = '/Volumes/main/default/default_volume/erikyzzhang/HOK/MOBA-HOK-train.json'\n",
    "use_databricks = True\n",
    "\n",
    "# 如果输出目录不存在，创建它\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "NUM_PROCESSES = torch.cuda.device_count()\n",
    "print(f\"We're using {NUM_PROCESSES} GPUs\")\n",
    "single_node_multi_gpu_ckpt_path = TorchDistributor(num_processes=NUM_PROCESSES, local_mode=True, use_gpu=True) \\\n",
    "    .run(\"./supervised-fine-tune-hok.py\", f'--model_name_or_path={model_name_or_path}', f\"--data_path={data_path}\",\n",
    "    f'--model_max_length={str(model_max_length)}', \n",
    "    f'--output_dir={output_dir}',\n",
    "    f'--use_databricks', use_databricks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d6a39b2-da1f-41d8-b7b5-052daef67985",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install sacrebleu sentencepiece -q\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b3dbab3-a329-4fb9-ac6f-70947cf2c735",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig, BitsAndBytesConfig\n",
    "import torch\n",
    "cache_dir = \"./\"\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16,)\n",
    "\n",
    "#/Volumes/main/default/default_volume/erikyzzhang/aya_pubg_ft_/checkpoint-59/\n",
    "# output_directory = \"/Volumes/main/default/default_volume/erikyzzhang/aya_hok_ft_\"\n",
    "output_directory = \"/Volumes/main/default/default_volume/erikyzzhang/HOK/models\"\n",
    "\n",
    "cache_dir = \"./\"\n",
    "model_name = \"CohereForAI/aya-23-8B\"\n",
    "peft_model_path = os.path.join(output_directory, \"checkpoint-382\")  # change checkpoint path\n",
    "\n",
    "peftconfig = PeftConfig.from_pretrained(peft_model_path)\n",
    "\n",
    "model_base = AutoModelForCausalLM.from_pretrained(peftconfig.base_model_name_or_path, quantization_config=nf4_config, \n",
    "                                             device_map = \"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_bos_token = True, add_eos_token = False, force_download=True,)\n",
    "\n",
    "new_model = PeftModel.from_pretrained(model_base, peft_model_path)\n",
    "\n",
    "print(\"Peft model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c76f685a-553e-4dc5-93cc-cc8fc42bc3e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import GenerationConfig\n",
    "import torch\n",
    "import csv\n",
    "\n",
    "def generate_response(prompt, model):\n",
    "  encoded_input = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
    "  model_inputs = encoded_input.to(\"cuda\")\n",
    "  with torch.no_grad():\n",
    "    generated_ids = model.generate(**model_inputs,\n",
    "                                  max_new_tokens=128,\n",
    "                                  min_new_tokens=1,\n",
    "                                  do_sample=False,\n",
    "                                  pad_token_id=tokenizer.eos_token_id)\n",
    "        \n",
    "  decoded_output = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "  return decoded_output[0].replace(prompt, \"\")\n",
    "\n",
    "def load_json(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading JSON file: {e}\")\n",
    "        return None\n",
    "\n",
    "translations = []\n",
    "references = []\n",
    "\n",
    "test_file = '/Volumes/main/default/default_volume/erikyzzhang/MOBA-HOK-cn-en-test.json'\n",
    "with open(test_file, 'r', encoding='utf-8') as file:\n",
    "    translation_pairs = json.load(file)\n",
    "print(len(translation_pairs))\n",
    "for pair in translation_pairs:\n",
    "    source_lang = pair['source_language']\n",
    "    source_text = pair['source_text']\n",
    "    target_lang = pair['target_language']\n",
    "    target_text = pair['target_text']\n",
    "    if source_text != 'nan' and target_text != 'nan':\n",
    "        example = \"Translate the  Text from \" + source_lang +  \" to \" + target_lang + \".\" + \"\\n\" +  source_lang + \": \" + source_text    \n",
    "        prompt = f\"<|START_OF_TURN_TOKEN|><|USER_TOKEN|>{example}<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>\"\n",
    "        references.append(target_text)\n",
    "        response = generate_response(prompt, new_model)\n",
    "        start_index = response.find(\"<|CHATBOT_TOKEN|>\")\n",
    "        response = response[start_index:].replace(\"<|CHATBOT_TOKEN|>\", \"\")\n",
    "        print(response)\n",
    "        translations.append(response)    \n",
    "print(len(translations))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f320eb4-3582-4fa0-88aa-7e737bba4a40",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(references[-5:])\n",
    "print(translations[-5:])\n",
    "print(len(references))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82f9c2e8-98a3-4945-bb16-e432d2f8c0be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "# Calculate BLEU\n",
    "bleu = sacrebleu.corpus_bleu(translations, [references])  # for spBLEU: tokenize='flores200'\n",
    "bleu = round(bleu.score, 2)\n",
    "print(\"BLEU:\", bleu)\n",
    "\n",
    "# Calculate chrF++\n",
    "chrf = sacrebleu.corpus_chrf(translations, [references], word_order=2)  # for chrF++ word_order=2\n",
    "chrf = round(chrf.score, 2)\n",
    "print(\"chrF++:\", chrf)\n",
    "\n",
    "# Calculate TER\n",
    "metric = sacrebleu.metrics.TER()\n",
    "ter = metric.corpus_score(translations, [references])\n",
    "ter = round(ter.score, 2)\n",
    "print(\"TER:\", ter)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "main_db_translation",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
